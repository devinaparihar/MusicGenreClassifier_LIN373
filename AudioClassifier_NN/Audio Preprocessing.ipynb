{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conda install -c conda-forge librosa\n",
    "#conda install -c conda-forge ffmpeg\n",
    "import librosa\n",
    "import numpy as np \n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "import urllib\n",
    "from pathlib import Path\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from requests import get\n",
    "from requests.exceptions import RequestException\n",
    "from contextlib import closing\n",
    "from os import listdir\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions to get features of each song and average them by album"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cid = \"enter your cid here\"\n",
    "secret = \"enter your client secret here\"\n",
    "client_credentials_manager = SpotifyClientCredentials(client_id=cid, client_secret=secret)\n",
    "sp = spotipy.Spotify(client_credentials_manager = client_credentials_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_get(url):\n",
    "    \"\"\"\n",
    "    Attempts to get the content at `url` by making an HTTP GET request.\n",
    "    If the content-type of response is some kind of HTML/XML, return the\n",
    "    text content, otherwise return None.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with closing(get(url, stream=True)) as resp:\n",
    "            if is_good_response(resp):\n",
    "                return resp.content\n",
    "            else:\n",
    "                return None\n",
    "\n",
    "    except RequestException as e:\n",
    "        log_error('Error during requests to {0} : {1}'.format(url, str(e)))\n",
    "        return None\n",
    "\n",
    "def is_good_response(resp):\n",
    "    \"\"\"\n",
    "    Returns True if the response seems to be HTML, False otherwise.\n",
    "    \"\"\"\n",
    "    content_type = resp.headers['Content-Type'].lower()\n",
    "    return (resp.status_code == 200 \n",
    "            and content_type is not None \n",
    "            and content_type.find('html') > -1)\n",
    "\n",
    "def log_error(e):\n",
    "    \"\"\"\n",
    "    It is always a good idea to log errors. \n",
    "    This function just prints them, but you can\n",
    "    make it do anything.\n",
    "    \"\"\"\n",
    "    print(e)\n",
    "    \n",
    "def get_Album_Averages(recording_mbids):\n",
    "    \n",
    "    chroma_stft_ = []\n",
    "    spec_cent_ = []\n",
    "    spec_bw_ = []\n",
    "    rolloff_ = []\n",
    "    zcr_ = []\n",
    "    mfcc_ = []\n",
    "    \n",
    "    for recording_mbid in recording_mbids:\n",
    "        #print(recording_mbid)\n",
    "        recording_mbid_url = 'https://musicbrainz.org/recording/' + recording_mbid\n",
    "        raw_html = simple_get(recording_mbid_url)\n",
    "        html = BeautifulSoup(raw_html, 'html.parser')\n",
    "        \n",
    "        for p in html.select('title'):\n",
    "            title = str(p.text)\n",
    "        #print(title)\n",
    "        \n",
    "        bad_chars = [';', ':', '!', \"*\", \"?\", \"/\", \"'\", \"\\\"\"] \n",
    "        \n",
    "        track_start = len(\"Recording\") + 2\n",
    "        track_stop = title.find(\"by\") - 2\n",
    "        trackName = title[track_start:track_stop]\n",
    "        \n",
    "        if \"’\" in trackName: \n",
    "            trackName = trackName.replace(\"’\", \"'\")\n",
    "            \n",
    "        for i in bad_chars : \n",
    "            trackName = trackName.replace(i, '') \n",
    "            \n",
    "        #print(trackName)\n",
    "        \n",
    "        artist_start = title.find(\"by\") + 3\n",
    "        artist_stop = title.find(\"-\") - 1\n",
    "        artistName = title[artist_start:artist_stop]\n",
    "\n",
    "        if \"’\" in artistName: \n",
    "            artistName = trackName.replace(\"’\", \"'\")\n",
    "            \n",
    "        for i in bad_chars : \n",
    "            artistName = artistName.replace(i, '') \n",
    "            \n",
    "        #print(artistName)\n",
    "                                          \n",
    "        song_status = get_mp3(trackName, artistName)\n",
    "        \n",
    "        if song_status == \"Song found\":\n",
    "            \n",
    "            #print(song_status)\n",
    "        \n",
    "            chroma_stft, spec_cent, spec_bw, rolloff, zcr, mfcc = extract_features(trackName)\n",
    "\n",
    "            chroma_stft_.append(chroma_stft)\n",
    "            spec_cent_.append(spec_cent)\n",
    "            spec_bw_.append(spec_bw)\n",
    "            rolloff_.append(rolloff)\n",
    "            zcr_.append(zcr)\n",
    "            mfcc_.append(mfcc)\n",
    "            \n",
    "        else:\n",
    "            print(song_status)\n",
    "    \n",
    "    #print(\"starting to average\")\n",
    "    if chroma_stft_ != []:\n",
    "        mfcc_1 = []\n",
    "        mfcc_2 = []\n",
    "        mfcc_3 = []\n",
    "        mfcc_4 = []\n",
    "        mfcc_5 = []\n",
    "\n",
    "        for i in mfcc_:\n",
    "            mfcc_1.append(i[0])\n",
    "            mfcc_2.append(i[1])\n",
    "            mfcc_3.append(i[2])\n",
    "            mfcc_4.append(i[3])\n",
    "            mfcc_5.append(i[4])\n",
    "\n",
    "        chroma_stft_avg = sum(chroma_stft_)/len(chroma_stft_)\n",
    "        spec_cent_avg = sum(spec_cent_)/len(spec_cent_)\n",
    "        spec_bw_avg = sum(spec_bw_)/len(spec_bw_)\n",
    "        rolloff_avg = sum(rolloff_)/len(rolloff_)\n",
    "        zcr_avg = sum(zcr_)/len(zcr_)\n",
    "        mfcc_1_avg = sum(mfcc_1)/len(mfcc_1)\n",
    "        mfcc_2_avg = sum(mfcc_2)/len(mfcc_2)\n",
    "        mfcc_3_avg = sum(mfcc_3)/len(mfcc_3)\n",
    "        mfcc_4_avg = sum(mfcc_4)/len(mfcc_4)\n",
    "        mfcc_5_avg = sum(mfcc_5)/len(mfcc_5)\n",
    "\n",
    "        album_averages = [chroma_stft_avg, spec_cent_avg, spec_bw_avg, rolloff_avg, zcr_avg, mfcc_1_avg, mfcc_2_avg, mfcc_3_avg, mfcc_4_avg, mfcc_5_avg]\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        album_averages = []\n",
    "\n",
    "    return album_averages\n",
    "\n",
    "def get_mp3(trackName, artistName):\n",
    "    search_string = trackName + \" \" + artistName\n",
    "    results = sp.search(q= search_string, limit=10, offset=0, type='track', market=None)\n",
    "    song_results = results['tracks']['items']\n",
    "    \n",
    "    if song_results != []:\n",
    "        #print(\"found the song!\")\n",
    "        song = song_results[0]\n",
    "        preview_url = song['preview_url']\n",
    "        #print(preview_url)\n",
    "        \n",
    "        if preview_url != None:\n",
    "            urllib.request.urlretrieve (preview_url, \"mp3s/\" + trackName + \".mp3\")\n",
    "            return \"Song found\"\n",
    "        \n",
    "        else: \n",
    "            return \"Preview not found\"\n",
    "        \n",
    "    else: \n",
    "        return \"Song not found\"\n",
    "    \n",
    "def extract_features(trackName):\n",
    "   \n",
    "    y, sr = librosa.load(\"mp3s/\"+ trackName + \".mp3\", duration = 15)\n",
    "    chroma_stft = np.mean(librosa.feature.chroma_stft(y=y, sr=sr))\n",
    "    spec_cent = np.mean(librosa.feature.spectral_centroid(y=y, sr=sr))\n",
    "    spec_bw = np.mean(librosa.feature.spectral_bandwidth(y=y, sr=sr))\n",
    "    rolloff = np.mean(librosa.feature.spectral_rolloff(y=y, sr=sr))\n",
    "    zcr = np.mean(librosa.feature.zero_crossing_rate(y))\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc = 5)\n",
    "    \n",
    "    mfcc_coef = []\n",
    "    for c in mfcc:\n",
    "        mfcc_coef.append(np.mean(c))\n",
    "             \n",
    "    return chroma_stft, spec_cent, spec_bw, rolloff, zcr, mfcc_coef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform MuMu Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = open('dfTracks.pkl','rb')\n",
    "track_dataset = pickle.load(infile)\n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(track_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a dataset with amazonids, recording mbids, and genres**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_df_dataset = {\"amazonIDs\": track_dataset['amazon_id'], \"recording_mbids\": track_dataset['recording_mbid'], \"genres\": track_dataset['genres']}\n",
    "track_df = pd.DataFrame(track_df_dataset)\n",
    "track_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Combine genres by amazonIDs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_df1 = track_df.groupby('amazonIDs')['genres'].apply(', '.join).reset_index()\n",
    "track_df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_df1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Combine recording_mbids by amazonIDs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_df2 = track_df.groupby('amazonIDs')['recording_mbids'].apply(', '.join).reset_index()\n",
    "track_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_df2.shape #should be the same shape as track_df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Combine df1 and df2 to have a new dataset that groups recording mbids and genres by its amazon ids**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataset = {\"amazonIDs\": track_df1['amazonIDs'], \"recording_mbids\": track_df2['recording_mbids'], \"genres\": track_df1['genres']}\n",
    "track_df = pd.DataFrame(new_dataset)\n",
    "track_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_df.to_csv('whole_audio_unprocessed_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reduce audio dataset to have same albums as text dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load audio data from step above**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_df = pd.read_csv('whole_audio_unprocessed_dataset.csv')\n",
    "audio_df = audio_df.drop(columns = ['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load preprocessed text data and match amazon ids then sort them st amazon ids are in the same order for both datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df = pd.read_pickle(\"df2000_babelfied.pkl\")\n",
    "entries_to_keep = text_df.amazonIDs.tolist()\n",
    "audio_df = audio_df[audio_df['amazonIDs'].isin(entries_to_keep)]\n",
    "text_df = text_df.sort_values(by=['amazonIDs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_df = audio_df.reset_index()\n",
    "audio_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_df.to_csv('audio_unprocessed_MLP.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df = text_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "text_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df.to_csv('text_babelified_processed_MLP.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_df = pd.read_csv('audio_unprocessed_MLP.csv')\n",
    "audio_df = audio_df.drop(columns = ['Unnamed: 0'])\n",
    "audio_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_stft = []\n",
    "spec_cent = []\n",
    "spec_bw = []\n",
    "rolloff = []\n",
    "zcr = []\n",
    "mfcc_1 = []\n",
    "mfcc_2 = []\n",
    "mfcc_3 = []\n",
    "mfcc_4 = []\n",
    "mfcc_5 = []\n",
    "useless_albums_Index = []\n",
    "useless_albums_index = []\n",
    "    \n",
    "for row in audio_df.itertuples():\n",
    "    recording_mbids = row.recording_mbids\n",
    "    split_recording_mbids = recording_mbids.split(', ')\n",
    "    album_averages = get_Album_Averages(split_recording_mbids)\n",
    "    \n",
    "    if album_averages != []:\n",
    "        chroma_stft.append(album_averages[0])\n",
    "        spec_cent.append(album_averages[1])\n",
    "        spec_bw.append(album_averages[2])\n",
    "        rolloff.append(album_averages[3])\n",
    "        zcr.append(album_averages[4])\n",
    "        mfcc_1.append(album_averages[5])\n",
    "        mfcc_2.append(album_averages[6])\n",
    "        mfcc_3.append(album_averages[7])\n",
    "        mfcc_4.append(album_averages[8])\n",
    "        mfcc_5.append(album_averages[9])\n",
    "        \n",
    "    else:\n",
    "        print(\"useless album:\", row.Index)\n",
    "        useless_albums_Index.append(row.Index)\n",
    "        useless_albums_index.append(row.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(chroma_stft))\n",
    "print(len(spec_cent))\n",
    "print(len(spec_bw))\n",
    "print(len(rolloff))\n",
    "print(len(zcr))\n",
    "print(len(mfcc_1))\n",
    "print(len(mfcc_2))\n",
    "print(len(mfcc_3))\n",
    "print(len(mfcc_4))\n",
    "print(len(mfcc_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(useless_albums_Index))\n",
    "print(useless_albums_Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(useless_albums_index))\n",
    "print(useless_albums_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped_audio_df = audio_df.drop(index = useless_albums_Index)\n",
    "print(dropped_audio_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped_audio_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped_audio_df = dropped_audio_df.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped_audio_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(track_Name)\n",
    "dataset = {\"index\": dropped_audio_df['index'], \"amazonIDs\": dropped_audio_df['amazonIDs'], \n",
    "           \"Chroma Stft\": chroma_stft, \"Spectral Centroid\": spec_cent, \"Spectral Bandwidth\": spec_bw, \n",
    "           \"Spectral Rolloff\": rolloff, \"ZCR\": zcr, \"MFCC 1\": mfcc_1, \"MFCC 2\": mfcc_2, \"MFCC 3\": mfcc_3, \n",
    "           \"MFCC 4\": mfcc_4, \"MFCC 5\": mfcc_5, \"Genres\": dropped_audio_df['genres']}\n",
    "df = pd.DataFrame(dataset)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('551_albums_audio.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
